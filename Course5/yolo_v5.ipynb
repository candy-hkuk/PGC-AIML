{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43311764-2533-437b-b9cd-d18e1d179a11",
   "metadata": {},
   "source": [
    "# YOLO5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde39991-26f7-409d-b114-d1e81dc0ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install cv2\n",
    "# this might be quicker from the cli\n",
    "!apt-get update && apt-get install ffmpeg libsm6 libxext6 -y\n",
    "!pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org opencv-python opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc385d-d8d5-4128-8a96-2fa209983292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import os\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b516c6-ac41-424a-96de-8c0780134806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter values\n",
    "TRAIN = True\n",
    "\n",
    "# Number of epochs to train for \n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f7aec-fbef-4d57-adc3-94ff4bb4e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to download files\n",
    "def download(url, save_name):\n",
    "    url = url\n",
    "    if not os.path.exists(save_name):\n",
    "        file = requests.get(url)\n",
    "        open(save_name, 'wb').write(file.content)\n",
    "    else:\n",
    "        print(\"file already exists, skipping download...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed38cc6-785b-449f-aa2c-a1ef4cc1b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull images from roboflow\n",
    "# data link : \"https://public.roboflow.com/ds/xKV14HbTF?key=aJzo7msVta\"\n",
    "\n",
    "if not os.path.exists('train'):\n",
    "    !/usr/bin/curl -L \"https://public.roboflow.com/ds/xKV14HbTF?key=aJzo7msVta\" > roboflow.zip; unzip roboflow.zip; \n",
    "    !rm roboflow.zip\n",
    "\n",
    "    dirs = ['train','valid','test']\n",
    "\n",
    "    for i, dir_name in enumerate(dirs):\n",
    "        all_image_names = sorted(os.listdir(f\"{dir_name}/images/\"))\n",
    "        for j, image_name in enumerate(all_image_names):\n",
    "            if(j % 2) == 0:\n",
    "                file_name = image_name.split('.jpg')[0]\n",
    "                os.remove(f\"{dir_name}/images/{image_name}\")\n",
    "                os.remove(f\"{dir_name}/labels/{file_name}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c4291-0e64-4529-b721-bac854c4dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the yolo5 repository\n",
    "# link : !git clone https://github.com/ultralytics/yolo5.git\n",
    "\n",
    "if not os.path.exists('yolov5'):\n",
    "    !git clone https://github.com/ultralytics/yolov5.git\n",
    "\n",
    "%cd yolov5/\n",
    "    \n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe5ad5d-ccfe-49a0-84b5-57ce79c1d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to store results\n",
    "def set_res_dir():\n",
    "    # dri\n",
    "    res_dir_count = len(glob.glob('runs/train/*'))\n",
    "    print(f\"Current number of result directories: {res_dir_count}\")\n",
    "    if TRAIN:\n",
    "        RES_DIR = f\"results_{res_dir_count+1}\"\n",
    "        print(RES_DIR)\n",
    "    else:\n",
    "        RES_DIR = f\"results_{res_dir_count}\"\n",
    "    return RES_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a81003-497a-4603-83f0-ac1749fde2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the model\n",
    "RES_DIR = set_res_dir()\n",
    "if TRAIN:\n",
    "    # VDC: python3\n",
    "    !python train.py --data ../data.yaml --weights yolov5s.pt \\\n",
    "    --img 640 --epochs {EPOCHS} --batch-size 16 --name {RES_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f8bfe-ad1f-47c8-b520-316c4204829f",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b38272-e581-45fc-af4f-f44326bec06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show validation predictions saved during training\n",
    "def show_valid_results(RES_DIR):\n",
    "    !ls runs/train/{RES_DIR}\n",
    "    EXP_PATH = f\" runs/train{RES_DIR}\"\n",
    "    validation_pred_images = glob.glob(f\"{EXP_PATH}/*_pred.jpg\")\n",
    "    print(validation_pred_images)\n",
    "    for pred_image in validation_pred_images:\n",
    "        image = cv2.imread(pred_image)\n",
    "        plt.figure(figsize=(19,16))\n",
    "        plt.imshow(image[:,:,::-1])\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc9e85-e6f8-44e4-aca3-efb060b2096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for inference on images\n",
    "def inference(RES_DIR, data_path):\n",
    "    infer_dir_count = len(glob.glob('runs/detect/*'))\n",
    "    print(f\" Current number of inference detection directories:{infer_dir_count}\")\n",
    "    INFER_DIR = f\"inference_{infer_dir_count+1}\"\n",
    "    print(INFER_DIR)\n",
    "\n",
    "    # Inference on images\n",
    "    !python detect.py --weights runs/train{RES_DIR}/weights/best.pt\\\n",
    "    --source {data_path} --name {INFER_DIR}\n",
    "\n",
    "    return INFER_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9b3a9-330b-4406-a715-2a4d7dca1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize inference images\n",
    "def visualise (INFER_DIR):\n",
    "    # visualize inference images\n",
    "    INFER_PATH = f\"runs/detect/{INFER_DIR}\"\n",
    "    infer_images = glob.glob(f\"{INFER_PATH}/*.jpg\")\n",
    "    print(infer_images)\n",
    "    for pred_image in infer_images:\n",
    "        image = cv2.imread(pred_image)\n",
    "        plt.figure(figsize=(19,16))\n",
    "        plt.imshow(image[:,:,::-1])\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606def34-9b88-4283-8ed0-80d9484d9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "show_valid_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166c08d-d202-4231-ba87-0221e4699760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading new files for inference\n",
    "download_file(\"https://learnopencv.s3.us-west-2.amazonaws.com/yolov5_inference_data.zip\",\n",
    "              \"inference_data.zip\")\n",
    "\n",
    "if not os.path.exists(\"inference_images\"):\n",
    "    !unzip -q \"inference_data.zip\"\n",
    "else:\n",
    "    print(\"dataset already present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f077d9-9912-4f62-a17a-6e88eb8086c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_INFER_DIR = inference(RES_DIR, 'inference_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e25a19-530f-4aeb-ba0e-4a3714b724ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize inference\n",
    "visualize(IMAGE_INFER_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
