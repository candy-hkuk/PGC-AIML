{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99638fa7-e74f-47a5-83b9-cefb694dfe23",
   "metadata": {},
   "source": [
    "# CNN with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff702bd-a382-49cc-b291-ca10946848ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using docker tensorflow/tensorflow:latest-juypter\n",
    "!pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ebddff-9711-4a94-9cc8-2bd6c2f40a8d",
   "metadata": {},
   "source": [
    "### Initialize the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89e9bf8-5f31-469c-8271-6b9c4b619ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mute Hardware optimzation messages\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bdc4c6-6054-4d40-b9b6-f149af315ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import tensorflow as tf\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown('# <span style=\"color:red\">'+string+'</span>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84fe37-ca8c-47d6-a764-3acdb754bd82",
   "metadata": {},
   "source": [
    "## 1st part: classify MNIST using simple model\n",
    "This MNIST dataset is a collection of 60000 handwritten digits and 10000 testing samples from the much larger NIST dataset. They have been size-normalized and centered in a fixed-size image for developer training.\n",
    "\n",
    "The first model is a simple Multi-layer perceptron (a type of Neural Network) to perform classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e0d97a-d6be-4a67-b4bb-35a186e25ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step \n"
     ]
    }
   ],
   "source": [
    "# Import the dataset from TensorFlow\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701287e1-a5a8-4a9c-825c-768280f80e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to improve optimization performance\n",
    "x_train, x_test = x_train /255.0, x_test /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885292f0-3bb3-492e-8727-33a52d8cbd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical Labels\n",
      "[5 0 4 1 9]\n"
     ]
    }
   ],
   "source": [
    "# Review the first few labels\n",
    "print(\"categorical Labels\")\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "568a8e12-7331-4cd3-8e67-644f14e38411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hot encoded labels\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]], shape=(5, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Encode the labels into a one-hot vector\n",
    "y_train = tf.one_hot(y_train, 10)\n",
    "y_test = tf.one_hot(y_test, 10)\n",
    "\n",
    "# Review one-hot encoded labels\n",
    "print(\"one hot encoded labels\")\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7420cfa-1f4a-4470-805f-49c3bedc0bab",
   "metadata": {},
   "source": [
    "Check the size of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b57201a-ce70-4bb4-b93b-8bed64107c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples: 60000\n",
      "number of test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"number of training examples:\", x_train.shape[0])\n",
    "print(\"number of test examples:\", x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c882d9-6ebb-4f8a-95af-859c4443f3fe",
   "metadata": {},
   "source": [
    "Shuffle the dataset to improve randomness on batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b881808-c6b5-4e43-8959-a4f3fdf5b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 09:23:38.701062: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 376320000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(50)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e9c9a-9795-42df-ae78-1eee3f7b5efa",
   "metadata": {},
   "source": [
    "### Convert 2D images to 1D Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a1a035-67bd-46c1-8cf6-ebfd7cfd384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the tensorflow flatten class for the reduction\n",
    "from tensorflow.keras.layers import Flatten\n",
    "flatten = Flatten(dtype = 'float32')\n",
    "\n",
    "print(\"original data shape\")\n",
    "print(x_train.shape)\n",
    "\n",
    "print(\"flattened shape\")\n",
    "print(flatten(x_train).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90cfba-8f25-4f23-b33c-d8861a0bb36d",
   "metadata": {},
   "source": [
    "### Convolution: 2D operation with native python\n",
    "\n",
    "The 2D convolution operation is defined as:\n",
    "\n",
    "<font size=\"4\">$$ I'= \\sum\\limits_{u,v} I(x-u,y-v)g(u,v) $$ </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00991e7-91b5-441f-8f43-3477bf6ac72d",
   "metadata": {},
   "source": [
    "1. _Example 1_ <br />\n",
    "    Applying 2D convolution on an image represented by a 3x3 matrix according to the function $$g = (\\begin{matrix}-1 & 1\\end{matrix})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98966d-2607-4c3c-8618-eddf4cc0635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal as sg\n",
    "\n",
    "I = [[255,  7,  3],\n",
    "     [212,240,  4],\n",
    "     [218,216,230],]\n",
    "\n",
    "g = [[-1,1]]\n",
    "\n",
    "print(\"Without zero padding\\n\")\n",
    "print('{0} \\n'.format(sg.convolve(I,g, \"valid\")))\n",
    "# The 'valid' argument states that the output consists only of those \n",
    "# elements that do not rely on the zero-padding\n",
    "\n",
    "print(\"With zero padding \\.\")\n",
    "print(sg.convolve(I,g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08492e4-5d84-4348-b8ea-d4eb136782f2",
   "metadata": {},
   "source": [
    "2. _Example 2_ <br />\n",
    "    With a more difficult case where $g = [\\begin{bmatrix}-1 & 1\\end{bmatrix},\\begin{bmatrix}2 & 3\\end{bmatrix}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d5125-58b5-4ed4-92fb-7a6f8fd4fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = [[-1, 1],\n",
    "     [ 2, 3]]\n",
    "\n",
    "print('With zero padding \\n')\n",
    "print('{0} \\n'.format(sg.convolve(I,g,\"full\")))\n",
    "# The output is the full discrete linear convolution of hte inputs.\n",
    "# It will use zero to complete the input matrix\n",
    "\n",
    "print('With zero padding(same) \\n')\n",
    "print('{0} \\n'.format(sg.convolve(I, g, \"same\")))\n",
    "# The output is teh full discrete linear convolution of the inputs.\n",
    "# It will use zero to complete the input matrix\n",
    "\n",
    "print('Without zero padding \\n')\n",
    "print(sg.convolve(I,g, 'valid'))\n",
    "# The 'valid' argument states that the output consists only of those\n",
    "# elements that do not rely on the zero-padding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948cab0-b1fd-4561-b8cf-27188bbe2eb3",
   "metadata": {},
   "source": [
    "## Coding with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d69a7e-8123-409f-a5e8-2a5e9edeee36",
   "metadata": {},
   "source": [
    "Assuming that we have a 10x10 image as input (tensor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fbab6-78fe-424f-9b88-71b20d49d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or as 4D tensor = [1,10,10,1] = [batch size, width, height, number of channels]\n",
    "input = tf.Variable(tf.random.normal([1,10,10,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ac92f-bd52-40cf-9ce2-862cf368b7b7",
   "metadata": {},
   "source": [
    "and we have a 3x3 filter (tensor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6153d99-a722-4547-9c8f-435e165402f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or as 4D tensor = [3,3,1,1] = [width, height, channels, number of filters]\n",
    "filter = tf.Variable(tf.random.normal([3,3,1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f24eb3-f9ca-41ff-bcbb-31e1a347b13c",
   "metadata": {},
   "source": [
    "If we were to process with zero padding in 'SAME' mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f662c2-0bc4-4214-a89d-82208f5d880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = tf.nn.conv2d(input, filter, strides=[1,1,1,1], padding='SAME')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c896873-2130-4881-a5c8-599d7208c11e",
   "metadata": {},
   "source": [
    "If we were to process without zero padding in 'VALID' mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbafc37-2dc5-4e55-b65f-ef9175a34cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "op2 = tf.nn.conv2d(input, filter, strides=[1,1,1,1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfa0a6-06c1-446c-a2d0-fb43a6e1d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input \\n\")\n",
    "print('{0} \\n'.format(input.numpy()))\n",
    "print(\"Filter/Kernel \\n\")\n",
    "print('{0} \\n'.format(filter.numpy()))\n",
    "print(\"Result/Feature Map with padding \\n\")\n",
    "print(op.numpy())\n",
    "print('\\n')\n",
    "print(\"Result/Feature Map with valid positions \\n\")\n",
    "print(op2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8433f0-8042-4d3a-a44d-47f7cde3e900",
   "metadata": {},
   "source": [
    "## Convolution applied on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044e1f5-a03d-4740-9f8b-fe30d2a57830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6321d08-1022-4588-b6bc-08d0736db6f7",
   "metadata": {},
   "source": [
    "### Testing on bird image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b846318-52fe-4a20-a9bf-c60725e132fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im = Image.open('bird.jpg')\n",
    "\n",
    "image_gr = im.convert(\"L\") \n",
    "# This method converts colour images into black and white using the\n",
    "# ITU-R 601-2 Luma transform\n",
    "print(\"\\n Original type: %r \\n\\n\" % image_gr)\n",
    "\n",
    "# Convert image to a matrix with values from 0 to 255 (uint8)\n",
    "arr = np.asarray(image_gr)\n",
    "print(\"After conversion to numerical representation: \\n\\n %r\" % arr)\n",
    "\n",
    "### activate matplotlib for Ipython\n",
    "%matplotlib inline\n",
    "\n",
    "### plot image\n",
    "imgplot = plt.imshow(arr)\n",
    "imgplot.set_cmap('gray')\n",
    "print(\"\\n Input image converted to gray scale: \\n\")\n",
    "plt.show(imgplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f905be-59e9-46c9-803b-d9955e31363a",
   "metadata": {},
   "source": [
    "Let's start experimenting using an edge detector kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac029b-f75f-479f-bbee-aa4182d09e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[ 0, 1, 0],\n",
    "                   [ 1,-4, 1],\n",
    "                   [ 0, 1, 0],])\n",
    "grad = signal.convolve2d(arr, kernel, mode='same', boundary='symm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d5d25-48f8-47be-ad25-e1a63a7dd985",
   "metadata": {},
   "source": [
    "Generate a feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca2d14-0204-4e29-a871-dba425efe74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print('GRADIENT MAGNITUDE - Feature map')\n",
    "\n",
    "fig, aux = plt.subplots(figsize=(10,10))\n",
    "aux.imshow(np.absolute(grad), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdedcd32-e3d6-4213-9115-b0637d74d238",
   "metadata": {},
   "source": [
    "Enhance and normalize the image pixels onto a 0 to 1 scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91efd0a3-a117-472d-80bb-ae6ffee6a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grad)\n",
    "\n",
    "grad_biases = np.absolute(grad) + 100\n",
    "grad_biases[grad_biases > 255] = 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b8b28-2f02-453e-b487-8944bc3525f1",
   "metadata": {},
   "source": [
    "Visualize the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30bfe2-4854-41b1-b75d-933104944670",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print('GRADIENT MAGNITUDE - Feature map')\n",
    "fig, aux = plt.subplots(figsize=(10,10))\n",
    "aux.imshow(np.absolute(grad_biases), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c1db2a-6162-441d-a724-dd20b51569c2",
   "metadata": {},
   "source": [
    "### Testing on image of a digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0488f6-bc88-49f3-9a78-cd1d66a2d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"num3.jpg\")\n",
    "\n",
    "image_gr = im.convert(\"L\")\n",
    "print(\"\\n Original type: %r \\n\\n\" % image_gr)\n",
    "\n",
    "# convert image to a matrix with values from 0 to 255 (uint8)\n",
    "arr = np.asarray(image_gr)\n",
    "print(\"After conversion to numerical representation: \\n\\n %r\" % arr)\n",
    "\n",
    "### activating matplotlib for Ipython\n",
    "%matplotlib inline\n",
    "\n",
    "### Plot image\n",
    "fig, aux = plt.subplots(figsize=(10,10))\n",
    "imgplot = plt.imshow(arr)\n",
    "imgplot.set_cmap('gray')\n",
    "print(\"\\n Input image converted to gray scale: \\n\")\n",
    "plt.show(imgplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018746c6-3241-4ae0-8795-50738223be68",
   "metadata": {},
   "source": [
    "Experiment using an edge detector kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103dc92-8b7d-4ad0-92ef-bd5045dac924",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[ 0, 1, 0],\n",
    "                   [ 1,-4, 1],\n",
    "                   [ 0, 1, 0],])\n",
    "grad = signal.convolve2d(arr, kernel, mode='same', boundary='symm')\n",
    "\n",
    "# Plot transformed image\n",
    "%matplotlib inline\n",
    "\n",
    "print('GRADIENT MAGNITUDE - Feature map')\n",
    "\n",
    "fig, aux = plt.subplots(figsize=(10,10))\n",
    "aux.imshow(np.absolute(grad), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a3ac0-29ac-4a8f-aed6-ad67ee1e1df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
